{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a2f9ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torch --index-url https://download.pytorch.org/whl/cpu --user\n",
    "# !pip3 install mosaicml-streaming --user\n",
    "# !pip3 install transformers --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dbd733e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from streaming import MDSWriter\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22dda0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from streaming.base.format.mds.encodings import Encoding, _encodings\n",
    "\n",
    "class UInt16(Encoding):\n",
    "    def encode(self, obj) -> bytes:\n",
    "        return obj.tobytes()\n",
    "\n",
    "    def decode(self, data: bytes):\n",
    "        return np.frombuffer(data, np.uint16)\n",
    "\n",
    "_encodings['uint16'] = UInt16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60354b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 256\n",
    "\n",
    "def read_dataset(train_file, block_size = block_size):\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        'malaysia-ai/bpe-tokenizer',\n",
    "    )\n",
    "    tokenizer.add_bos_token = False\n",
    "    tokenizer.add_eos_token = False\n",
    "    text_column_name = 'text'\n",
    "    temp = []\n",
    "    with open(train_file) as fopen:\n",
    "        for l in fopen:\n",
    "            l = json.loads(l)\n",
    "            tokenized = tokenizer(l)['input_ids']\n",
    "            temp.extend(tokenized)\n",
    "            while len(temp) >= block_size:\n",
    "                block = temp[:block_size]\n",
    "                temp = temp[block_size:]\n",
    "                if len(block) == block_size:\n",
    "                    yield np.array(block).astype(np.uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d76c9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://huggingface.co/datasets/malaysia-ai/dedup-text-dataset/resolve/main/wikipedia-2023-10-01.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a3211ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3536,  3146,   352,    55, 13338, 29575,    29, 30871,  1512,\n",
       "       27499,  7928,   779,    30,   383,   884,   272,    29, 18963,\n",
       "         101,   119,   170,   102,   227,   170,   101,   124, 18963,\n",
       "         101,   120,   170,   102,   239,   170,   101,   126,   170,\n",
       "         101,   127,   170,   102,   234,    12,  2150,  2200,   939,\n",
       "         918,  2309,    16,  9584,  3146,    16, 10115,  4978,   359,\n",
       "         295,  1676,  2802,  2309,  7724,  1424,    15,   313,  1427,\n",
       "        2309,  7159,   295, 21329,    15,  1627,    15,   726,   323,\n",
       "        9291,    15,  1313,   847,   327,  3814,   295,  4528,   287,\n",
       "         413,   661,    72,   323,  7148,  6774,   295,   332,   371,\n",
       "       29887,  1056, 19997,   323,  8466,    17,  7902, 29589,  2309,\n",
       "        3146, 18769,    76,   822,   918,   411,  2129,  2655, 29589,\n",
       "         352,  5090,  1810, 25920,  2655,   743,  1168, 10643,  2309,\n",
       "        1627,    12,   510, 17182,  2604,  6514, 12048,  4225, 13335,\n",
       "          17,   224,   202, 11038,  2200,   939,   918,  2309,    16,\n",
       "        9584,   313,  2497,  6453,  2244,   295,  4225, 13335,    15,\n",
       "        2309,  3146,  1502, 10255, 20404,   313,  5233,   295,  1222,\n",
       "          16,  5966,  5457,  8767,   532,  5765,   323,  5620,  4096,\n",
       "        2309,  3146,   295,  1222,    16,  5966,   871,    17,  1733,\n",
       "         726,    15, 10255,  1206,  9584,  3146,     5,  2150, 10255,\n",
       "        1206,  3306,   381,   966,     5,   449,  6342,   275, 16618,\n",
       "         260,  7159,  2309, 14472,  1222,   726,    15,  5757, 10255,\n",
       "        1206,  9584,   726,     5,   647,  1206,  9584,  3146,   726,\n",
       "           5, 27567,  2244, 11414,  2293,   313,  1305,  1064,   515,\n",
       "       14788,   295,  4918,  2476,   726,    17,  1733,  9291,    15,\n",
       "        3536,  3146,  1502,  6440,  2309, 14472,   532,  2602,   313,\n",
       "        1305,  1427,  2200,   939,   918,  4033,  2309,  7159,   352,\n",
       "       10248,  1021,  2309,  7159,   901,  2150,  2309, 11130,    15,\n",
       "        2309,  9404,    15,   323], dtype=uint16)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(read_dataset('wikipedia-2023-10-01.jsonl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf2e4cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = {\n",
    "    'input_ids': 'uint16',\n",
    "}\n",
    "compression = 'zstd'\n",
    "hashes = 'sha1', 'xxh64'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0fde452",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_root = 'indexed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de07c682",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "249563it [04:28, 929.51it/s] \n"
     ]
    }
   ],
   "source": [
    "with MDSWriter(out=out_root, columns=columns, compression=compression, hashes=hashes) as out:\n",
    "    for block in tqdm(read_dataset(train_file = 'wikipedia-2023-10-01.jsonl')):\n",
    "        sample = {\n",
    "            'input_ids': block\n",
    "        }\n",
    "        out.write(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7eab2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['S3_ENDPOINT_URL'] = 'http://minio:9000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e61ea218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streaming\n",
    "\n",
    "streaming.base.util.clean_stale_shared_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5e4c7a5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from streaming import StreamingDataset\n",
    "\n",
    "remote_dir = 's3://train/indexed'\n",
    "\n",
    "local_dir = 'local_dir'\n",
    "dataset = StreamingDataset(local=local_dir, remote=remote_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
